{
  "slug": "test-generator",
  "category": "coding",
  "title": "Unit Test Generator",
  "description": "Unit Test Generator prompt - Generate comprehensive test suites with edge cases, mocks, and 100% coverage. Never ship untested code again.",
  "tags": [
    "ChatGPT prompts",
    "Claude prompts",
    "free prompts",
    "technology prompts"
  ],
  "prompt": "You are a test-driven development expert who writes comprehensive, maintainable test suites. Create unit tests that catch bugs, document behavior, and ensure code reliability.\n\nI need comprehensive unit tests for the following code:\n\nTEST CONTEXT:\nLanguage: [PROGRAMMING LANGUAGE]\nTesting Framework: [JEST / PYTEST / JUNIT / MOCHA / ETC]\nCoverage Target: [PERCENTAGE]\nMock Strategy: [MOCK ALL EXTERNAL / MINIMAL MOCKS / ETC]\n\nCode to Test:\n```[language]\n[PASTE YOUR CODE HERE]\n```\n\nDependencies/Imports:\n```[language]\n[PASTE RELEVANT DEPENDENCIES IF ANY]\n```\n\nPlease generate:\n\n1. COMPLETE TEST SUITE\nFull test implementation:\n```[language]\n// ============================================\n// UNIT TESTS FOR [MODULE/CLASS NAME]\n// ============================================\n\nimport { describe, test, expect, beforeEach, afterEach, jest } from '[framework]';\nimport { [ClassToTest] } from './[module]';\n// Import mocks and dependencies\n\n// Mock external dependencies\njest.mock('./externalService', () => ({\n    // Mock implementation\n}));\n\ndescribe('[ClassToTest]', () => {\n    let instance;\n    let mockDependency;\n    \n    // Setup and teardown\n    beforeEach(() => {\n        // Reset mocks\n        jest.clearAllMocks();\n        \n        // Create fresh instance\n        mockDependency = {\n            method: jest.fn()\n        };\n        instance = new [ClassToTest](mockDependency);\n    });\n    \n    afterEach(() => {\n        // Cleanup\n    });\n    \n    // ========== HAPPY PATH TESTS ==========\n    describe('Happy Path', () => {\n        test('should [expected behavior] when [condition]', () => {\n            // Arrange\n            const input = /* test data */;\n            const expected = /* expected result */;\n            \n            // Act\n            const result = instance.method(input);\n            \n            // Assert\n            expect(result).toEqual(expected);\n            expect(mockDependency.method).toHaveBeenCalledWith(/* args */);\n            expect(mockDependency.method).toHaveBeenCalledTimes(1);\n        });\n        \n        test('should [another behavior] when [another condition]', () => {\n            // Test implementation\n        });\n    });\n    \n    // ========== EDGE CASES ==========\n    describe('Edge Cases', () => {\n        test('should handle empty input', () => {\n            // Test empty arrays, strings, objects\n        });\n        \n        test('should handle null/undefined', () => {\n            // Test null and undefined inputs\n        });\n        \n        test('should handle maximum values', () => {\n            // Test with MAX_SAFE_INTEGER, etc\n        });\n        \n        test('should handle minimum values', () => {\n            // Test with negative numbers, zero\n        });\n        \n        test('should handle special characters', () => {\n            // Test with unicode, emojis, etc\n        });\n    });\n    \n    // ========== ERROR CASES ==========\n    describe('Error Handling', () => {\n        test('should throw error when [invalid condition]', () => {\n            // Arrange\n            const invalidInput = /* invalid data */;\n            \n            // Act & Assert\n            expect(() => {\n                instance.method(invalidInput);\n            }).toThrow('[Expected Error Message]');\n        });\n        \n        test('should handle async errors gracefully', async () => {\n            // Mock rejection\n            mockDependency.asyncMethod.mockRejectedValue(new Error('Network error'));\n            \n            // Test error handling\n            await expect(instance.asyncMethod()).rejects.toThrow('Network error');\n        });\n    });\n    \n    // ========== ASYNC TESTS ==========\n    describe('Async Operations', () => {\n        test('should handle async operations correctly', async () => {\n            // Arrange\n            const mockData = { /* data */ };\n            mockDependency.fetchData.mockResolvedValue(mockData);\n            \n            // Act\n            const result = await instance.asyncMethod();\n            \n            // Assert\n            expect(result).toEqual(/* expected */);\n        });\n        \n        test('should handle concurrent async calls', async () => {\n            // Test race conditions\n        });\n    });\n    \n    // ========== INTEGRATION POINTS ==========\n    describe('Integration Points', () => {\n        test('should interact correctly with [dependency]', () => {\n            // Test dependency interactions\n        });\n        \n        test('should emit correct events', () => {\n            // Test event emissions\n        });\n    });\n});\n```\n\n2. TEST COVERAGE MATRIX\nWhat's being tested:\n```\nMethod: [methodName]\n✅ Normal inputs\n✅ Edge cases (null, undefined, empty)\n✅ Boundary values\n✅ Error conditions\n✅ Async scenarios\n✅ Performance (if applicable)\n\nMethod: [anotherMethod]\n✅ [Test scenarios]\n...\n\nCOVERAGE SUMMARY:\n- Lines: 95%\n- Branches: 90%\n- Functions: 100%\n- Statements: 92%\n```\n\n3. MOCK IMPLEMENTATIONS\nReusable mocks:\n```[language]\n// __mocks__/externalService.js\nexport const mockExternalService = {\n    fetchData: jest.fn(() => Promise.resolve({ data: 'mock' })),\n    sendData: jest.fn(() => Promise.resolve({ success: true })),\n    // Add failure scenarios\n    fetchDataFailure: jest.fn(() => Promise.reject(new Error('Network error')))\n};\n\n// Mock factories for different scenarios\nexport const createMockUser = (overrides = {}) => ({\n    id: 1,\n    name: 'Test User',\n    email: 'test@example.com',\n    ...overrides\n});\n\nexport const createMockDatabase = () => ({\n    query: jest.fn(),\n    insert: jest.fn(),\n    update: jest.fn(),\n    delete: jest.fn()\n});\n```\n\n4. PARAMETERIZED TESTS\nTest multiple scenarios efficiently:\n```[language]\ndescribe.each([\n    ['empty string', '', 0],\n    ['single word', 'hello', 1],\n    ['multiple words', 'hello world', 2],\n    ['with punctuation', 'hello, world!', 2],\n    ['with numbers', 'hello 123 world', 3],\n])('wordCount(%s)', (description, input, expected) => {\n    test(`returns ${expected} for ${description}`, () => {\n        expect(wordCount(input)).toBe(expected);\n    });\n});\n```\n\n5. PERFORMANCE TESTS\nEnsure code performs well:\n```[language]\ntest('should complete within performance budget', () => {\n    const startTime = performance.now();\n    const largeDataSet = Array(10000).fill(0).map((_, i) => i);\n    \n    // Act\n    instance.processData(largeDataSet);\n    \n    // Assert\n    const endTime = performance.now();\n    const executionTime = endTime - startTime;\n    expect(executionTime).toBeLessThan(100); // ms\n});\n```\n\n6. SNAPSHOT TESTS\nFor UI or complex objects:\n```[language]\ntest('should match snapshot', () => {\n    const result = instance.generateReport(data);\n    expect(result).toMatchSnapshot();\n});\n\ntest('should match inline snapshot', () => {\n    expect(instance.formatData(input)).toMatchInlineSnapshot(`\n        Object {\n            \"formatted\": true,\n            \"data\": Array [1, 2, 3]\n        }\n    `);\n});\n```\n\n7. TEST UTILITIES\nHelper functions for tests:\n```[language]\n// testUtils.js\nexport const waitFor = (condition, timeout = 5000) => {\n    // Polling utility\n};\n\nexport const setupTestDatabase = async () => {\n    // Database setup for tests\n};\n\nexport const cleanupTestData = async () => {\n    // Cleanup after tests\n};\n\nexport const assertDeepEquals = (actual, expected) => {\n    // Custom deep equality assertion\n};\n```\n\n8. CI/CD INTEGRATION\nRun tests in pipeline:\n```yaml\n# .github/workflows/test.yml\nname: Tests\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Install dependencies\n        run: npm install\n      - name: Run tests\n        run: npm test -- --coverage\n      - name: Upload coverage\n        uses: codecov/codecov-action@v2\n```\n\n9. TEST DOCUMENTATION\nExplain test approach:\n```markdown\n## Testing Strategy\n- Unit tests for all public methods\n- Integration tests for API endpoints\n- E2E tests for critical user flows\n\n## Running Tests\nnpm test           # Run all tests\nnpm test:watch     # Watch mode\nnpm test:coverage  # With coverage report\n\n## Writing Tests\n- Follow AAA pattern (Arrange, Act, Assert)\n- One assertion per test when possible\n- Use descriptive test names\n```\n\n10. COMMON TESTING PATTERNS\nReusable patterns:\n- **Builder Pattern** for test data\n- **Object Mother** for complex objects\n- **Test Data Factory** for consistency\n- **Custom Matchers** for domain logic\n- **Test Fixtures** for static data\n\nPlease ensure tests are:\n- Independent (no shared state)\n- Repeatable (same result every time)\n- Fast (milliseconds not seconds)\n- Descriptive (clear failure messages)\n- Maintainable (easy to update)"
}